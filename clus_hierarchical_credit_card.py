# -*- coding: utf-8 -*-
"""Clus-Hierarchical-Credit-Card.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BOd8VnaNwfQUEX2mmoOpDlRS4cgth1EG

<h1 align=center><font size = 5>Hierarchical Clustering Analysis of Credit Card Customers</font></h1>

<img src="https://image.cnbcfm.com/api/v1/image/103951797-GettyImages-532419122.jpg?v=1530195940&w=1920&h=1080" height=500 width=1000 alt="https://www.cnbc.com/2017/05/18/5-questions-to-ask-when-choosing-a-credit-card.html">

<small>Picture Source: <a href="https://www.cnbc.com/2017/05/18/5-questions-to-ask-when-choosing-a-credit-card.html">CNBC</a></small>

<br>

## Summary  

Welcome to the Clus-Hierarchical-Credit-Card project! This project focuses on applying hierarchical clustering analysis to a Credit Card customers dataset to uncover valuable insights and customer segments based on their credit card usage patterns, spending behaviors, and demographics.

<br>

In summary, this project focuses on applying hierarchical clustering techniques to the Credit Card customers dataset to uncover customer segments with similar attributes and behaviors. By leveraging the insights gained from this analysis, businesses can make informed decisions to enhance their services, refine their marketing strategies, and provide a more personalized experience to their credit card customers.  

<br>

## Introduction

In today's data-driven world, understanding customer behavior and preferences is essential for businesses to thrive. The Credit Card customers dataset, available on Kaggle, offers valuable insights into the characteristics, spending patterns, and credit card usage of customers. Analyzing this dataset using hierarchical clustering techniques can provide valuable segmentation and customer profiling, enabling businesses to tailor their strategies and services to specific customer segments.

<br>

The Credit Card customers dataset captures a wide range of features, including customer *demographics*, *credit card attributes*, and *transactional data*. By leveraging this rich dataset, we can uncover hidden structures and patterns within the customer base, leading to a deeper understanding of customer segments, preferences, and needs.
*Hierarchical clustering* is a powerful technique for grouping similar customers based on their attributes and behaviors. It constructs a hierarchical structure, known as a *dendrogram*, that reveals clusters at different levels of similarity. By utilizing a hierarchical approach, **we can identify meaningful customer segments that share common characteristics, enabling businesses to develop targeted marketing campaigns, improve customer experiences, and optimize their business strategies.**

<br>

Throughout this analysis, we will perform data preprocessing steps, such as handling missing values, encoding categorical variables, and scaling numerical features. Next, we will apply hierarchical clustering algorithms to the prepared dataset, enabling us to uncover distinct customer segments based on similarities in their credit card usage patterns, spending behaviors, and demographics. By conducting hierarchical clustering on the Credit Card customers dataset, we aim to provide actionable insights to businesses in the credit card industry. The identified customer segments can assist in customer retention, acquisition strategies, personalized marketing campaigns, and the development of tailored credit card offerings. Understanding the unique needs and preferences of different customer segments can help businesses enhance customer satisfaction, increase customer loyalty, and drive business growth.

## Summary

In summary, this project focuses on applying hierarchical clustering techniques to the Credit Card customers dataset to uncover customer segments with similar attributes and behaviors. By leveraging the insights gained from this analysis, businesses can make informed decisions to enhance their services, refine their marketing strategies, and provide a more personalized experience to their credit card customers.

<br>

<h2>Keywords</h2>

<ul>
	<li>Hierarchical Clustering</li>
	<li>Credit Card</li>
	<li>Clustering</li>
	<li>Customer Segmentation</li>
	<li>Customer Patterns & Analysis</li>
</ul>

<br>

<h1>Objective for this Notebook</h1>

<div class="alert alert-block alert-info" style="margin-top: 20px">
<div class="alert alert-block alert-info" style="margin-top: 20px">
  <ol>
      <li><a href="https://#importing_libraries">Importing Libraries</a></li>
      <li><a href="https://#data_preprocessing">Data Preprocessing</a></li>  
      <li><a href="https://#data_cleaning">Data Cleaning</a></li>
      <li><a href="https://#clustering_using_scipy">Clustering Using SciPy</a></li>
      <li><a href="https://#clustering_using_skl">Clustering using Scikit-learn</a></li>
  </ol>
</div>
<br>

<p></p>
Estimated Time Needed: <strong>20 min</strong>
</div>

## Importing libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from scipy.cluster import hierarchy
from matplotlib import pyplot as plt
import warnings
warnings.filterwarnings("ignore")
# %matplotlib inline

"""## Data Preprocessing

### Download data

[The Credit Card customers dataset](https://www.kaggle.com/datasets/sakshigoyal7/credit-card-customers), which is essential for conducting hierarchical clustering analysis, can be obtained from the Kaggle platform. Kaggle is a well-known online community and data science platform that provides a wide range of datasets for various analytical tasks. To access the Credit Card customers dataset, visit the Kaggle website and navigate to the dataset's page. The dataset, created by a user named sakshigoyal7, is publicly available for download. On the dataset page, click on the **Download** button to initiate the download process. Once the download is complete, you will have a local copy of the Credit Card customers dataset on your device.

<br>

The dataset contains valuable information related to customer demographics, credit card attributes, and transactional data. It serves as a comprehensive resource for analyzing customer behavior, identifying customer segments, and making data-driven decisions to optimize business strategies in the credit card industry.

<br>

By obtaining the Credit Card customers dataset from Kaggle, you gain access to a rich collection of data that can be leveraged to uncover patterns, segment customers, and gain insights into credit card usage behaviors. This dataset provides an opportunity to delve into the world of customer profiling and segmentation, enabling businesses to refine their offerings, develop targeted marketing campaigns, and enhance customer satisfaction.
"""

!unzip -q /content/archive.zip

"""### Read data

Let's read dataset to see what features the manufacturer has collected about the existing models.

"""

filename = '/content/BankChurners.csv'

"""Before using the data, we should inspect it. You can see performs the data exploration and preprocessing on the below."""

df = pd.read_csv(filename)
df = df.iloc[:, :-2]
print("Shape of dataset: ", df.shape)

"""We don't need CLIENTNUM which is client number. We can drop it."""

df = df.drop('CLIENTNUM', axis=1)

df.head(10)

df.dtypes

"""Check the count of missing values in each column."""

df.isnull().sum()

"""Compute summary statistics for numerical columns."""

df.describe().T

plt.figure(figsize=(16, 7), dpi=300)
plt.title('Customer Age Distribution')
df['Customer_Age'].hist()
plt.show()

"""## Hierarchical Clustering - Agglomerative

Hierarchical clustering, specifically the agglomerative approach, is a type of clustering algorithm used to group similar objects or data points based on their pairwise similarities or distances. It is a bottom-up clustering technique that starts with each data point as an individual cluster and iteratively merges clusters until a termination condition is met. We will be looking at a clustering technique, which is <b>Agglomerative Hierarchical Clustering</b>. Remember that agglomerative is the bottom up approach.<br>

### Feature selection

Let's select our feature set:
"""

featureset = df[['Credit_Limit', 'Avg_Open_To_Buy', 'Customer_Age', 'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Months_on_book']]

"""The feature sets include:


1.   Credit Limit on the Credit Card (**Credit_Limit**).
2.   Open to Buy Credit Line (Average of last 12 months) (**Avg_Open_To_Buy**).
3.   Demographic variable - Customer's Age in Years (**Customer_Age**).
4.   Total no. of products held by the customer (**Total_Relationship_Count**).
5.   No. of months inactive in the last 12 months (**Months_Inactive_12_mon**).
6.   Period of relationship with bank (**Months_on_book**).

### Normalization

Now we can normalize the feature set. **MinMaxScaler** transforms features by scaling each feature to a given range. It is by default (0, 1). That is, this estimator scales and translates each feature individually such that it is between zero and one.
"""

from sklearn.preprocessing import MinMaxScaler
x = featureset.values
min_max_scaler = MinMaxScaler()
feature_mtx = min_max_scaler.fit_transform(x)

feature_mtx[0:5]

desired_columns = ['Credit_Limit', 'Avg_Open_To_Buy', 'Customer_Age',
                   'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Months_on_book']

fig, axs = plt.subplots(3, 2, figsize=(16, 20), dpi=200)

for i, ax in enumerate(axs.flatten()):
    label = desired_columns[i]
    ax.hist(df[df['Gender'] == 'M'][label], color='red', label="Male",
            alpha=0.7, density=True, bins=15)
    ax.hist(df[df['Gender'] == 'F'][label], color='green', label="Female",
            alpha=0.7, density=True, bins=15)
    ax.set_title(label)
    ax.set_ylabel("Normalized value")
    ax.set_xlabel(label)
    ax.legend()

plt.tight_layout()
plt.show()

"""### Clustering using scikit-learn

Let's redo it again, but this time using the scikit-learn package:

"""

from sklearn.metrics.pairwise import euclidean_distances
dist_matrix = euclidean_distances(feature_mtx, feature_mtx)
print(dist_matrix)

Z_using_dist_matrix = hierarchy.linkage(dist_matrix, 'complete')

Z_using_dist_matrix

"""### Plotting dendrogram

A *dendrogram* is a tree-like diagram commonly used in *hierarchical clustering analysis* to illustrate the arrangement and grouping of objects or samples based on their similarity or dissimilarity. It visually represents the *hierarchical relationships* between data points, displaying how they cluster and merge together as the analysis progresses. In a dendrogram, the objects or samples are represented by the leaves or terminal nodes of the tree-like structure. The branches and nodes of *the dendrogram* depict the clustering hierarchy. The height or length of the branches reflects the dissimilarity between clusters or individual data points. The longer the branch, the greater the dissimilarity.

<br>

*The dendrogram* starts with individual data points as separate clusters and progressively merges them based on their similarity or distance. The process continues until all the data points are merged into a single cluster at the root of *the dendrogram*. Dendrograms are commonly used to assist in identifying the optimal number of clusters within a dataset by visually inspecting the structure of *the dendrogram*. The height at which clusters merge can indicate the dissimilarity threshold for forming distinct clusters. This information helps in making decisions about the appropriate number of clusters to consider for subsequent analysis or interpretation.

<br>

Dendrograms are useful not only in clustering analysis but also in other fields such as *biology, taxonomy, and data visualization*, where hierarchical relationships need to be displayed and analyzed. They provide a concise and informative representation of hierarchical clustering results, aiding in the understanding and interpretation of complex data structures.
"""

import scipy
import pylab

fig = pylab.figure(figsize=(10, 50), dpi=300)
def llf(id):
    return '[%s %s]' % (df['Education_Level'][id], df['Card_Category'][id])

dendro = hierarchy.dendrogram(Z_using_dist_matrix, leaf_label_func=llf, leaf_rotation=0, leaf_font_size=1, orientation = 'right')

"""Now, we can use the `AgglomerativeClustering` function from scikit-learn library to cluster the dataset. The `AgglomerativeClustering` performs a hierarchical clustering using a bottom up approach. The linkage criteria determines the metric used for the merge strategy:

*   Ward minimizes the sum of squared differences within all clusters. It is a variance-minimizing approach and in this sense is similar to the k-means objective function but tackled with an agglomerative hierarchical approach.
*   Maximum or complete linkage minimizes the maximum distance between observations of pairs of clusters.
*   Average linkage minimizes the average of the distances between all observations of pairs of clusters.

"""

from sklearn.cluster import AgglomerativeClustering
agglom = AgglomerativeClustering(n_clusters=6, linkage='complete')
agglom.fit(dist_matrix)

agglom.labels_

"""We can add a new field to our dataframe to show the cluster of each row:

"""

df['cluster_'] = agglom.labels_
df.head()

import matplotlib.cm as cm
n_clusters = max(agglom.labels_)+1
colors = cm.rainbow(np.linspace(0, 1, n_clusters))
cluster_labels = list(range(0, n_clusters))

plt.figure(figsize=(16, 14))

for color, label in zip(colors, cluster_labels):
    subset = df[df.cluster_ == label]
    for i in subset.index:
        plt.text(subset.Months_on_book[i], subset.Customer_Age[i], str(subset['Education_Level'][i]), rotation=25, fontsize=5)
    plt.scatter(subset.Months_on_book, subset.Customer_Age, s=subset.Total_Trans_Ct*5, c=color, label='cluster'+str(label),alpha=0.5)

plt.legend()
plt.title('Clusters')
plt.xlabel('Months on Book')
plt.ylabel('Customer Age')

"""After applying label encoding to spesified column, the `encoder.classes_` attribute is used to retrieve the unique categories in each column, and `encoder.transform(encoder.classes_)` is used to get the corresponding encoded values.

Using encoder for all columns:
"""

# For all columns

# from sklearn.preprocessing import LabelEncoder

# encoder = LabelEncoder()
# for column in df.columns:
#     if df[column].dtype == 'object' or df[column].dtype.name == 'category':
#         df[column] = encoder.fit_transform(df[column])
#         print(f"Column: {column}")
#         for category, value in zip(encoder.classes_, encoder.transform(encoder.classes_)):
#             print(f"Category: {category}, Encoded Value: {value}")
#         print("-" * 50)

"""Using encoder for spesific columns:"""

from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()

columns = ['Attrition_Flag', 'Education_Level', 'Marital_Status', 'Income_Category']

for column in columns:
    if df[column].dtype == 'object' or df[column].dtype.name == 'category':
        df[column] = encoder.fit_transform(df[column])
        print(f"Column: {column}")
        for category, value in zip(encoder.classes_, encoder.transform(encoder.classes_)):
            print(f"Category: {category}, Encoded Value: {value}")
        print("-" * 50)

"""Now we can look at the characteristics of each cluster:

"""

param = 'Education_Level' #@param ['Attrition_Flag', 'Education_Level', 'Marital_Status', 'Income_Category']

agg_card = df.groupby(['cluster_', param])['Credit_Limit', 'Avg_Open_To_Buy', 'Customer_Age',
                   'Total_Relationship_Count', 'Months_Inactive_12_mon', 'Months_on_book'].mean()
agg_card

df.to_csv('BankChruners_clustered.csv', index=False)

# !pip freeze > requirements.txt

"""## Contact Me
<p>If you have something to say to me please contact me:</p>

<ul>
  <li>Twitter: <a href="https://twitter.com/Doguilmak">Doguilmak</a></li>
  <li>Mail address: doguilmak@gmail.com</li>
</ul>
"""

from datetime import datetime
print(f"Changes have been made to the project on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")